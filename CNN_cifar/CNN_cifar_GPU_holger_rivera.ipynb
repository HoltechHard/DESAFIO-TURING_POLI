{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "BYmxJcq8cA7S"
   },
   "source": [
    "# ALGORITMO DE IA-4: REDE NEURAL CONVOLUCIONAL (CNN) \n",
    "# EXECUTADA SOBRE 1 TESLA K-80 GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tQPUzugkcA7U"
   },
   "source": [
    "ENUNCIADO:  \n",
    "Implementar uma Rede Neural Convolucional (CNN) usando as bibliotecas TensorFlow e Keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1sEMHdPccA7W"
   },
   "source": [
    "# CASO 03: DATASET CIFAR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "cAS7ssTZcA7W"
   },
   "source": [
    "CIFAR-10 é um conjunto de dados que consiste em 60'000 imagens coloridas de 32x32 distribuidas em 10 classes, 6'000 imagens por classe. São 50'000 imagens no conjunto de treinamento e 10'000 imagens para teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 272
    },
    "colab_type": "code",
    "id": "XVTZgY-mSTOS",
    "outputId": "24cc537b-fda9-4c65-8fae-0c5e63eb634e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[name: \"/device:CPU:0\"\n",
       " device_type: \"CPU\"\n",
       " memory_limit: 268435456\n",
       " locality {\n",
       " }\n",
       " incarnation: 8579116533636927463, name: \"/device:GPU:0\"\n",
       " device_type: \"GPU\"\n",
       " memory_limit: 11281989632\n",
       " locality {\n",
       "   bus_id: 1\n",
       "   links {\n",
       "   }\n",
       " }\n",
       " incarnation: 14198208983889221277\n",
       " physical_device_desc: \"device: 0, name: Tesla K80, pci bus id: 0000:00:04.0, compute capability: 3.7\"]"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#verificar conexão com GPU de GoogleColab\n",
    "import tensorflow as tf\n",
    "tf.test.gpu_device_name()\n",
    "\n",
    "#verificar que GPU estou usando \n",
    "from tensorflow.python.client import device_lib\n",
    "device_lib.list_local_devices()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sI1zjUhWcA7Y"
   },
   "source": [
    "1) Importar livrarías/formatear dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ncO-61M-cA7a"
   },
   "outputs": [],
   "source": [
    "#importar livrarías\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "from scipy.misc import toimage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "46eXdrwWcA7f",
    "outputId": "d352fabe-f1b0-4d03-e85a-be3cbf4642cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170500096/170498071 [==============================] - 98s 1us/step\n"
     ]
    }
   ],
   "source": [
    "#carregar conjunto de treinamento/teste\n",
    "(X_train, Y_train), (X_test, Y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "EnzcUhnjcA7j"
   },
   "source": [
    "2) FASE DE PREPROCESSAMENTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iGHhe2WccA7k"
   },
   "outputs": [],
   "source": [
    "#Aplicar redimensionamento sobre os dados para obter uma matriz [#samples] x [width] x [weight] x [channels]\n",
    "\n",
    "#conjunto de treinamento\n",
    "x_train = X_train.reshape(X_train.shape[0], 32, 32, 3)\n",
    "\n",
    "#conjunto de teste\n",
    "x_test = X_test.reshape(X_test.shape[0], 32, 32, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8I5d5XU6cA7p"
   },
   "outputs": [],
   "source": [
    "#converter os tipos de dado para float32\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZHclV0idcA7t"
   },
   "outputs": [],
   "source": [
    "#standarização dos dados: x_std = (x-ux)/std(x)\n",
    "x_train = (x_train - np.mean(x_train))/np.std(x_train)\n",
    "x_test = (x_test - np.mean(x_test))/np.std(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "KQOXZcH_cA7x",
    "outputId": "d6fdccd6-22a4-4344-ccc9-2068724cfe4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Variáveis na matriz de caraterísticas:  96\n",
      "#Dim. Matriz de Caraterísticas - train:  (50000, 32, 32, 3)\n",
      "#Dim. Matriz de Caraterísticas - test:  (10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "#informação sobre a matriz de caraterísticas:\n",
    "dim_inputs = x_train.shape[2] * x_train.shape[3]\n",
    "print('#Variáveis na matriz de caraterísticas: ', dim_inputs)\n",
    "print('#Dim. Matriz de Caraterísticas - train: ', x_train.shape)\n",
    "print('#Dim. Matriz de Caraterísticas - test: ', x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "lrpb0F6xcA75",
    "outputId": "c568da6c-6888-443e-bbc1-2c4ee6531f29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output train:  [0 1 2 3 4 5 6 7 8 9]\n",
      "Classes possíveis:  10\n",
      "Dim. Matriz de Saídas - train:  (50000, 10)\n",
      "Dim. Matriz de Saídas - test:  (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "#visualizar saídas/classes\n",
    "print('Output train: ', np.unique(Y_train))\n",
    "\n",
    "#transformar o vetor de classes em uma matriz binária de classes [0...9]\n",
    "y_train = keras.utils.to_categorical(Y_train, len(np.unique(Y_train)))\n",
    "y_test = keras.utils.to_categorical(Y_test, len(np.unique(Y_test)))\n",
    "\n",
    "#informação sobre a matriz de saídas: \n",
    "dim_outputs = len(np.unique(Y_train))\n",
    "print('Classes possíveis: ', dim_outputs)\n",
    "print('Dim. Matriz de Saídas - train: ', y_train.shape)\n",
    "print('Dim. Matriz de Saídas - test: ', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZexwbkbTcA8A"
   },
   "source": [
    "3) FASE DE APRENDIZADO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F45iJjJVcA8B"
   },
   "outputs": [],
   "source": [
    "#importar livrarías\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import Dense\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "from keras import regularizers\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kaLugw6ZcA8G"
   },
   "source": [
    "Define-se a seguinte arquitetura de Rede Neural Convolucional para o CIFAR-10:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7GhqEbmNcA8H"
   },
   "source": [
    "![texto alternativo](img/cifar_architect.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 9370
    },
    "colab_type": "code",
    "id": "EiWcQrk3cA8K",
    "outputId": "42d870ce-0d5a-4956-ee0e-66911717e7c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 32)        896       \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        9248      \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 64)        18496     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 64)        36928     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 128)         73856     \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 128)         147584    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 2048)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                20490     \n",
      "=================================================================\n",
      "Total params: 309,290\n",
      "Trainable params: 308,394\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:Variable *= will be deprecated. Use `var.assign(var * other)` if you want assignment to the variable value or `x = x * y` if you want a new python Tensor object.\n",
      "Epoch 1/250\n",
      "781/781 [==============================] - 50s 63ms/step - loss: 1.8886 - acc: 0.4207 - val_loss: 1.4836 - val_acc: 0.5559\n",
      "Epoch 2/250\n",
      "781/781 [==============================] - 47s 60ms/step - loss: 1.2334 - acc: 0.5943 - val_loss: 1.0310 - val_acc: 0.6800\n",
      "Epoch 3/250\n",
      "781/781 [==============================] - 45s 58ms/step - loss: 1.0487 - acc: 0.6589 - val_loss: 0.9535 - val_acc: 0.7013\n",
      "Epoch 4/250\n",
      "781/781 [==============================] - 45s 58ms/step - loss: 0.9528 - acc: 0.6951 - val_loss: 0.8949 - val_acc: 0.7292\n",
      "Epoch 5/250\n",
      "781/781 [==============================] - 45s 57ms/step - loss: 0.8797 - acc: 0.7211 - val_loss: 0.8340 - val_acc: 0.7485\n",
      "Epoch 6/250\n",
      "781/781 [==============================] - 45s 57ms/step - loss: 0.8242 - acc: 0.7414 - val_loss: 0.8470 - val_acc: 0.7468\n",
      "Epoch 7/250\n",
      "781/781 [==============================] - 44s 57ms/step - loss: 0.7937 - acc: 0.7557 - val_loss: 0.7868 - val_acc: 0.7710\n",
      "Epoch 8/250\n",
      "781/781 [==============================] - 45s 58ms/step - loss: 0.7585 - acc: 0.7654 - val_loss: 0.6801 - val_acc: 0.7982\n",
      "Epoch 9/250\n",
      "781/781 [==============================] - 43s 55ms/step - loss: 0.7332 - acc: 0.7753 - val_loss: 0.7077 - val_acc: 0.7925\n",
      "Epoch 10/250\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.7077 - acc: 0.7847 - val_loss: 0.7231 - val_acc: 0.7930\n",
      "Epoch 11/250\n",
      "781/781 [==============================] - 43s 56ms/step - loss: 0.6893 - acc: 0.7915 - val_loss: 0.6882 - val_acc: 0.7991\n",
      "Epoch 12/250\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.6682 - acc: 0.8001 - val_loss: 0.6382 - val_acc: 0.8180\n",
      "Epoch 13/250\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.6639 - acc: 0.8009 - val_loss: 0.5867 - val_acc: 0.8310\n",
      "Epoch 14/250\n",
      "781/781 [==============================] - 44s 57ms/step - loss: 0.6418 - acc: 0.8082 - val_loss: 0.6298 - val_acc: 0.8228\n",
      "Epoch 15/250\n",
      "781/781 [==============================] - 45s 58ms/step - loss: 0.6317 - acc: 0.8101 - val_loss: 0.6407 - val_acc: 0.8144\n",
      "Epoch 16/250\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.6175 - acc: 0.8174 - val_loss: 0.6311 - val_acc: 0.8281\n",
      "Epoch 17/250\n",
      "781/781 [==============================] - 41s 52ms/step - loss: 0.6066 - acc: 0.8214 - val_loss: 0.6657 - val_acc: 0.8167\n",
      "Epoch 18/250\n",
      "781/781 [==============================] - 44s 56ms/step - loss: 0.5964 - acc: 0.8250 - val_loss: 0.6272 - val_acc: 0.8253\n",
      "Epoch 19/250\n",
      "781/781 [==============================] - 46s 59ms/step - loss: 0.5932 - acc: 0.8252 - val_loss: 0.5349 - val_acc: 0.8533\n",
      "Epoch 20/250\n",
      "781/781 [==============================] - 45s 58ms/step - loss: 0.5812 - acc: 0.8302 - val_loss: 0.5509 - val_acc: 0.8486\n",
      "Epoch 21/250\n",
      "781/781 [==============================] - 43s 55ms/step - loss: 0.5715 - acc: 0.8329 - val_loss: 0.5574 - val_acc: 0.8466\n",
      "Epoch 22/250\n",
      "781/781 [==============================] - 44s 56ms/step - loss: 0.5720 - acc: 0.8337 - val_loss: 0.5819 - val_acc: 0.8402\n",
      "Epoch 23/250\n",
      "781/781 [==============================] - 41s 52ms/step - loss: 0.5633 - acc: 0.8348 - val_loss: 0.5176 - val_acc: 0.8556\n",
      "Epoch 24/250\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.5472 - acc: 0.8412 - val_loss: 0.5633 - val_acc: 0.8454\n",
      "Epoch 25/250\n",
      "781/781 [==============================] - 41s 52ms/step - loss: 0.5452 - acc: 0.8420 - val_loss: 0.5227 - val_acc: 0.8551\n",
      "Epoch 26/250\n",
      "781/781 [==============================] - 41s 52ms/step - loss: 0.5442 - acc: 0.8418 - val_loss: 0.5222 - val_acc: 0.8563\n",
      "Epoch 27/250\n",
      "781/781 [==============================] - 44s 57ms/step - loss: 0.5361 - acc: 0.8448 - val_loss: 0.5457 - val_acc: 0.8491\n",
      "Epoch 28/250\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.5273 - acc: 0.8462 - val_loss: 0.5481 - val_acc: 0.8470\n",
      "Epoch 29/250\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.5239 - acc: 0.8469 - val_loss: 0.5018 - val_acc: 0.8613\n",
      "Epoch 30/250\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.5194 - acc: 0.8491 - val_loss: 0.5591 - val_acc: 0.8513\n",
      "Epoch 31/250\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.5208 - acc: 0.8474 - val_loss: 0.5178 - val_acc: 0.8594\n",
      "Epoch 32/250\n",
      "781/781 [==============================] - 43s 56ms/step - loss: 0.5123 - acc: 0.8510 - val_loss: 0.5269 - val_acc: 0.8558\n",
      "Epoch 33/250\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.5079 - acc: 0.8535 - val_loss: 0.5197 - val_acc: 0.8568\n",
      "Epoch 34/250\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.5029 - acc: 0.8560 - val_loss: 0.5143 - val_acc: 0.8596\n",
      "Epoch 35/250\n",
      "781/781 [==============================] - 40s 52ms/step - loss: 0.4979 - acc: 0.8568 - val_loss: 0.5066 - val_acc: 0.8614\n",
      "Epoch 36/250\n",
      "781/781 [==============================] - 44s 57ms/step - loss: 0.4969 - acc: 0.8567 - val_loss: 0.4852 - val_acc: 0.8677\n",
      "Epoch 37/250\n",
      "781/781 [==============================] - 46s 58ms/step - loss: 0.4899 - acc: 0.8605 - val_loss: 0.5105 - val_acc: 0.8603\n",
      "Epoch 38/250\n",
      "781/781 [==============================] - 44s 56ms/step - loss: 0.4849 - acc: 0.8607 - val_loss: 0.5013 - val_acc: 0.8625\n",
      "Epoch 39/250\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.4845 - acc: 0.8611 - val_loss: 0.5263 - val_acc: 0.8608\n",
      "Epoch 40/250\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.4836 - acc: 0.8605 - val_loss: 0.4912 - val_acc: 0.8671\n",
      "Epoch 41/250\n",
      "781/781 [==============================] - 44s 57ms/step - loss: 0.4790 - acc: 0.8623 - val_loss: 0.5057 - val_acc: 0.8629\n",
      "Epoch 42/250\n",
      "781/781 [==============================] - 43s 55ms/step - loss: 0.4717 - acc: 0.8678 - val_loss: 0.4779 - val_acc: 0.8700\n",
      "Epoch 43/250\n",
      "781/781 [==============================] - 41s 52ms/step - loss: 0.4636 - acc: 0.8667 - val_loss: 0.4927 - val_acc: 0.8674\n",
      "Epoch 44/250\n",
      "781/781 [==============================] - 44s 56ms/step - loss: 0.4680 - acc: 0.8653 - val_loss: 0.4996 - val_acc: 0.8609\n",
      "Epoch 45/250\n",
      "781/781 [==============================] - 44s 57ms/step - loss: 0.4656 - acc: 0.8674 - val_loss: 0.4655 - val_acc: 0.8735\n",
      "Epoch 46/250\n",
      "781/781 [==============================] - 43s 55ms/step - loss: 0.4633 - acc: 0.8687 - val_loss: 0.4785 - val_acc: 0.8716\n",
      "Epoch 47/250\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.4618 - acc: 0.8680 - val_loss: 0.4652 - val_acc: 0.8771\n",
      "Epoch 48/250\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.4546 - acc: 0.8708 - val_loss: 0.5165 - val_acc: 0.8584\n",
      "Epoch 49/250\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.4533 - acc: 0.8702 - val_loss: 0.5199 - val_acc: 0.8596\n",
      "Epoch 50/250\n",
      "781/781 [==============================] - 44s 57ms/step - loss: 0.4553 - acc: 0.8695 - val_loss: 0.4669 - val_acc: 0.8768\n",
      "Epoch 51/250\n",
      "781/781 [==============================] - 45s 58ms/step - loss: 0.4495 - acc: 0.8722 - val_loss: 0.4662 - val_acc: 0.8733\n",
      "Epoch 52/250\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.4397 - acc: 0.8732 - val_loss: 0.4727 - val_acc: 0.8712\n",
      "Epoch 53/250\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.4283 - acc: 0.8777 - val_loss: 0.4572 - val_acc: 0.8789\n",
      "Epoch 54/250\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.4201 - acc: 0.8826 - val_loss: 0.4410 - val_acc: 0.8822\n",
      "Epoch 55/250\n",
      "781/781 [==============================] - 43s 56ms/step - loss: 0.4266 - acc: 0.8787 - val_loss: 0.4600 - val_acc: 0.8775\n",
      "Epoch 56/250\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.4167 - acc: 0.8818 - val_loss: 0.4626 - val_acc: 0.8755\n",
      "Epoch 57/250\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.4190 - acc: 0.8823 - val_loss: 0.4688 - val_acc: 0.8739\n",
      "Epoch 58/250\n",
      "781/781 [==============================] - 45s 57ms/step - loss: 0.4162 - acc: 0.8827 - val_loss: 0.4563 - val_acc: 0.8774\n",
      "Epoch 59/250\n",
      "781/781 [==============================] - 44s 56ms/step - loss: 0.4163 - acc: 0.8823 - val_loss: 0.4456 - val_acc: 0.8828\n",
      "Epoch 60/250\n",
      "781/781 [==============================] - 41s 52ms/step - loss: 0.4172 - acc: 0.8817 - val_loss: 0.4556 - val_acc: 0.8787\n",
      "Epoch 61/250\n",
      "781/781 [==============================] - 41s 52ms/step - loss: 0.4132 - acc: 0.8829 - val_loss: 0.4494 - val_acc: 0.8803\n",
      "Epoch 62/250\n",
      "781/781 [==============================] - 43s 55ms/step - loss: 0.4163 - acc: 0.8828 - val_loss: 0.4452 - val_acc: 0.8836\n",
      "Epoch 63/250\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.4035 - acc: 0.8869 - val_loss: 0.4571 - val_acc: 0.8810\n",
      "Epoch 64/250\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.4079 - acc: 0.8843 - val_loss: 0.4638 - val_acc: 0.8754\n",
      "Epoch 65/250\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.4068 - acc: 0.8846 - val_loss: 0.4476 - val_acc: 0.8796\n",
      "Epoch 66/250\n",
      "781/781 [==============================] - 45s 58ms/step - loss: 0.4039 - acc: 0.8857 - val_loss: 0.4505 - val_acc: 0.8815\n",
      "Epoch 67/250\n",
      "781/781 [==============================] - 43s 56ms/step - loss: 0.4048 - acc: 0.8837 - val_loss: 0.4573 - val_acc: 0.8767\n",
      "Epoch 68/250\n",
      "781/781 [==============================] - 43s 55ms/step - loss: 0.4016 - acc: 0.8860 - val_loss: 0.4464 - val_acc: 0.8812\n",
      "Epoch 69/250\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.4011 - acc: 0.8866 - val_loss: 0.4416 - val_acc: 0.8824\n",
      "Epoch 70/250\n",
      "781/781 [==============================] - 41s 52ms/step - loss: 0.4036 - acc: 0.8842 - val_loss: 0.4413 - val_acc: 0.8841\n",
      "Epoch 71/250\n",
      "781/781 [==============================] - 44s 56ms/step - loss: 0.4022 - acc: 0.8869 - val_loss: 0.4209 - val_acc: 0.8861\n",
      "Epoch 72/250\n",
      "781/781 [==============================] - 43s 55ms/step - loss: 0.3915 - acc: 0.8900 - val_loss: 0.4340 - val_acc: 0.8863\n",
      "Epoch 73/250\n",
      "781/781 [==============================] - 43s 55ms/step - loss: 0.4034 - acc: 0.8864 - val_loss: 0.4336 - val_acc: 0.8828\n",
      "Epoch 74/250\n",
      "781/781 [==============================] - 41s 52ms/step - loss: 0.3975 - acc: 0.8868 - val_loss: 0.4325 - val_acc: 0.8850\n",
      "Epoch 75/250\n",
      "781/781 [==============================] - 41s 52ms/step - loss: 0.3944 - acc: 0.8889 - val_loss: 0.4456 - val_acc: 0.8806\n",
      "Epoch 76/250\n",
      "781/781 [==============================] - 44s 56ms/step - loss: 0.3922 - acc: 0.8881 - val_loss: 0.4502 - val_acc: 0.8804\n",
      "Epoch 77/250\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3904 - acc: 0.8891 - val_loss: 0.4298 - val_acc: 0.8856\n",
      "Epoch 78/250\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3921 - acc: 0.8884 - val_loss: 0.4546 - val_acc: 0.8778\n",
      "Epoch 79/250\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.3953 - acc: 0.8876 - val_loss: 0.4461 - val_acc: 0.8792\n",
      "Epoch 80/250\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3891 - acc: 0.8886 - val_loss: 0.4390 - val_acc: 0.8846\n",
      "Epoch 81/250\n",
      "781/781 [==============================] - 46s 58ms/step - loss: 0.3869 - acc: 0.8920 - val_loss: 0.4337 - val_acc: 0.8850\n",
      "Epoch 82/250\n",
      "781/781 [==============================] - 45s 57ms/step - loss: 0.3873 - acc: 0.8895 - val_loss: 0.4323 - val_acc: 0.8855\n",
      "Epoch 83/250\n",
      "781/781 [==============================] - 43s 55ms/step - loss: 0.3819 - acc: 0.8922 - val_loss: 0.4235 - val_acc: 0.8862\n",
      "Epoch 84/250\n",
      "781/781 [==============================] - 40s 52ms/step - loss: 0.3874 - acc: 0.8903 - val_loss: 0.4335 - val_acc: 0.8859\n",
      "Epoch 85/250\n",
      "781/781 [==============================] - 43s 55ms/step - loss: 0.3842 - acc: 0.8921 - val_loss: 0.4327 - val_acc: 0.8856\n",
      "Epoch 86/250\n",
      "781/781 [==============================] - 44s 56ms/step - loss: 0.3842 - acc: 0.8906 - val_loss: 0.4390 - val_acc: 0.8840\n",
      "Epoch 87/250\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3831 - acc: 0.8912 - val_loss: 0.4248 - val_acc: 0.8868\n",
      "Epoch 88/250\n",
      "781/781 [==============================] - 44s 56ms/step - loss: 0.3828 - acc: 0.8940 - val_loss: 0.4323 - val_acc: 0.8865\n",
      "Epoch 89/250\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.3804 - acc: 0.8925 - val_loss: 0.4147 - val_acc: 0.8883\n",
      "Epoch 90/250\n",
      "781/781 [==============================] - 44s 56ms/step - loss: 0.3810 - acc: 0.8932 - val_loss: 0.4320 - val_acc: 0.8839\n",
      "Epoch 91/250\n",
      "781/781 [==============================] - 43s 55ms/step - loss: 0.3868 - acc: 0.8907 - val_loss: 0.4359 - val_acc: 0.8845\n",
      "Epoch 92/250\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.3733 - acc: 0.8933 - val_loss: 0.4212 - val_acc: 0.8870\n",
      "Epoch 93/250\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.3789 - acc: 0.8912 - val_loss: 0.4248 - val_acc: 0.8873\n",
      "Epoch 94/250\n",
      "781/781 [==============================] - 44s 57ms/step - loss: 0.3806 - acc: 0.8918 - val_loss: 0.4297 - val_acc: 0.8871\n",
      "Epoch 95/250\n",
      "781/781 [==============================] - 45s 58ms/step - loss: 0.3765 - acc: 0.8919 - val_loss: 0.4299 - val_acc: 0.8863\n",
      "Epoch 96/250\n",
      "781/781 [==============================] - 43s 55ms/step - loss: 0.3788 - acc: 0.8916 - val_loss: 0.4292 - val_acc: 0.8850\n",
      "Epoch 97/250\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3737 - acc: 0.8945 - val_loss: 0.4290 - val_acc: 0.8848\n",
      "Epoch 98/250\n",
      "781/781 [==============================] - 41s 52ms/step - loss: 0.3765 - acc: 0.8924 - val_loss: 0.4357 - val_acc: 0.8866\n",
      "Epoch 99/250\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3783 - acc: 0.8917 - val_loss: 0.4352 - val_acc: 0.8850\n",
      "Epoch 100/250\n",
      "781/781 [==============================] - 44s 56ms/step - loss: 0.3715 - acc: 0.8948 - val_loss: 0.4242 - val_acc: 0.8858\n",
      "Epoch 101/250\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3755 - acc: 0.8926 - val_loss: 0.4300 - val_acc: 0.8863\n",
      "Epoch 102/250\n",
      "781/781 [==============================] - 43s 54ms/step - loss: 0.3698 - acc: 0.8947 - val_loss: 0.4203 - val_acc: 0.8874\n",
      "Epoch 103/250\n",
      "781/781 [==============================] - 43s 55ms/step - loss: 0.3733 - acc: 0.8938 - val_loss: 0.4330 - val_acc: 0.8817\n",
      "Epoch 104/250\n",
      "781/781 [==============================] - 43s 55ms/step - loss: 0.3663 - acc: 0.8969 - val_loss: 0.4384 - val_acc: 0.8808\n",
      "Epoch 105/250\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3696 - acc: 0.8951 - val_loss: 0.4141 - val_acc: 0.8894\n",
      "Epoch 106/250\n",
      "781/781 [==============================] - 44s 57ms/step - loss: 0.3708 - acc: 0.8943 - val_loss: 0.4160 - val_acc: 0.8891\n",
      "Epoch 107/250\n",
      "781/781 [==============================] - 43s 56ms/step - loss: 0.3650 - acc: 0.8963 - val_loss: 0.4296 - val_acc: 0.8855\n",
      "Epoch 108/250\n",
      "781/781 [==============================] - 43s 54ms/step - loss: 0.3653 - acc: 0.8968 - val_loss: 0.4318 - val_acc: 0.8865\n",
      "Epoch 109/250\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3687 - acc: 0.8953 - val_loss: 0.4201 - val_acc: 0.8892\n",
      "Epoch 110/250\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3658 - acc: 0.8967 - val_loss: 0.4267 - val_acc: 0.8864\n",
      "Epoch 111/250\n",
      "781/781 [==============================] - 44s 56ms/step - loss: 0.3660 - acc: 0.8949 - val_loss: 0.4303 - val_acc: 0.8856\n",
      "Epoch 112/250\n",
      "781/781 [==============================] - 43s 55ms/step - loss: 0.3641 - acc: 0.8960 - val_loss: 0.4122 - val_acc: 0.8901\n",
      "Epoch 113/250\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3643 - acc: 0.8962 - val_loss: 0.4190 - val_acc: 0.8898\n",
      "Epoch 114/250\n",
      "781/781 [==============================] - 41s 52ms/step - loss: 0.3637 - acc: 0.8967 - val_loss: 0.4178 - val_acc: 0.8889\n",
      "Epoch 115/250\n",
      "781/781 [==============================] - 41s 52ms/step - loss: 0.3658 - acc: 0.8969 - val_loss: 0.4230 - val_acc: 0.8874\n",
      "Epoch 116/250\n",
      "781/781 [==============================] - 43s 55ms/step - loss: 0.3660 - acc: 0.8965 - val_loss: 0.4196 - val_acc: 0.8880\n",
      "Epoch 117/250\n",
      "781/781 [==============================] - 45s 57ms/step - loss: 0.3606 - acc: 0.8978 - val_loss: 0.4240 - val_acc: 0.8858\n",
      "Epoch 118/250\n",
      "781/781 [==============================] - 43s 55ms/step - loss: 0.3627 - acc: 0.8974 - val_loss: 0.4347 - val_acc: 0.8850\n",
      "Epoch 119/250\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3694 - acc: 0.8949 - val_loss: 0.4352 - val_acc: 0.8859\n",
      "Epoch 120/250\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3603 - acc: 0.8968 - val_loss: 0.4333 - val_acc: 0.8866\n",
      "Epoch 121/250\n",
      "781/781 [==============================] - 44s 56ms/step - loss: 0.3606 - acc: 0.8981 - val_loss: 0.4279 - val_acc: 0.8887\n",
      "Epoch 122/250\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3607 - acc: 0.8965 - val_loss: 0.4158 - val_acc: 0.8908\n",
      "Epoch 123/250\n",
      "781/781 [==============================] - 41s 52ms/step - loss: 0.3593 - acc: 0.8987 - val_loss: 0.4190 - val_acc: 0.8904\n",
      "Epoch 124/250\n",
      "781/781 [==============================] - 45s 58ms/step - loss: 0.3628 - acc: 0.8967 - val_loss: 0.4215 - val_acc: 0.8900\n",
      "Epoch 125/250\n",
      "781/781 [==============================] - 41s 52ms/step - loss: 0.3573 - acc: 0.8986 - val_loss: 0.4156 - val_acc: 0.8912\n",
      "Epoch 126/250\n",
      "781/781 [==============================] - 41s 52ms/step - loss: 0.3605 - acc: 0.8968 - val_loss: 0.4313 - val_acc: 0.8870\n",
      "Epoch 127/250\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3583 - acc: 0.8987 - val_loss: 0.4304 - val_acc: 0.8871\n",
      "Epoch 128/250\n",
      "781/781 [==============================] - 44s 57ms/step - loss: 0.3545 - acc: 0.8976 - val_loss: 0.4183 - val_acc: 0.8884\n",
      "Epoch 129/250\n",
      "781/781 [==============================] - 43s 56ms/step - loss: 0.3572 - acc: 0.8981 - val_loss: 0.4140 - val_acc: 0.8894\n",
      "Epoch 130/250\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3590 - acc: 0.8975 - val_loss: 0.4283 - val_acc: 0.8869\n",
      "Epoch 131/250\n",
      "781/781 [==============================] - 44s 56ms/step - loss: 0.3587 - acc: 0.8981 - val_loss: 0.4157 - val_acc: 0.8905\n",
      "Epoch 132/250\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.3598 - acc: 0.8971 - val_loss: 0.4197 - val_acc: 0.8889\n",
      "Epoch 133/250\n",
      "781/781 [==============================] - 43s 55ms/step - loss: 0.3541 - acc: 0.8987 - val_loss: 0.4332 - val_acc: 0.8850\n",
      "Epoch 134/250\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.3523 - acc: 0.9001 - val_loss: 0.4087 - val_acc: 0.8925\n",
      "Epoch 135/250\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3564 - acc: 0.8980 - val_loss: 0.4202 - val_acc: 0.8883\n",
      "Epoch 136/250\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3547 - acc: 0.8992 - val_loss: 0.4151 - val_acc: 0.8881\n",
      "Epoch 137/250\n",
      "781/781 [==============================] - 44s 56ms/step - loss: 0.3586 - acc: 0.8974 - val_loss: 0.4053 - val_acc: 0.8929\n",
      "Epoch 138/250\n",
      "781/781 [==============================] - 40s 52ms/step - loss: 0.3509 - acc: 0.9012 - val_loss: 0.4047 - val_acc: 0.8930\n",
      "Epoch 139/250\n",
      "781/781 [==============================] - 43s 55ms/step - loss: 0.3565 - acc: 0.8979 - val_loss: 0.4265 - val_acc: 0.8866\n",
      "Epoch 140/250\n",
      "781/781 [==============================] - 45s 57ms/step - loss: 0.3534 - acc: 0.8994 - val_loss: 0.4170 - val_acc: 0.8888\n",
      "Epoch 141/250\n",
      "781/781 [==============================] - 43s 55ms/step - loss: 0.3507 - acc: 0.9005 - val_loss: 0.4200 - val_acc: 0.8882\n",
      "Epoch 142/250\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.3552 - acc: 0.8973 - val_loss: 0.4062 - val_acc: 0.8924\n",
      "Epoch 143/250\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3460 - acc: 0.9025 - val_loss: 0.4144 - val_acc: 0.8919\n",
      "Epoch 144/250\n",
      "781/781 [==============================] - 44s 56ms/step - loss: 0.3533 - acc: 0.8975 - val_loss: 0.4219 - val_acc: 0.8894\n",
      "Epoch 145/250\n",
      "781/781 [==============================] - 43s 55ms/step - loss: 0.3491 - acc: 0.9004 - val_loss: 0.4083 - val_acc: 0.8935\n",
      "Epoch 146/250\n",
      "781/781 [==============================] - 44s 56ms/step - loss: 0.3473 - acc: 0.9013 - val_loss: 0.4171 - val_acc: 0.8892\n",
      "Epoch 147/250\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.3489 - acc: 0.9000 - val_loss: 0.4146 - val_acc: 0.8907\n",
      "Epoch 148/250\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3485 - acc: 0.9009 - val_loss: 0.4190 - val_acc: 0.8883\n",
      "Epoch 149/250\n",
      "781/781 [==============================] - 43s 55ms/step - loss: 0.3460 - acc: 0.9023 - val_loss: 0.4220 - val_acc: 0.8873\n",
      "Epoch 150/250\n",
      "781/781 [==============================] - 41s 52ms/step - loss: 0.3468 - acc: 0.9012 - val_loss: 0.4137 - val_acc: 0.8910\n",
      "Epoch 151/250\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3506 - acc: 0.9004 - val_loss: 0.4095 - val_acc: 0.8928\n",
      "Epoch 152/250\n",
      "781/781 [==============================] - 43s 55ms/step - loss: 0.3448 - acc: 0.9012 - val_loss: 0.4259 - val_acc: 0.8873\n",
      "Epoch 153/250\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3432 - acc: 0.9026 - val_loss: 0.4156 - val_acc: 0.8918\n",
      "Epoch 154/250\n",
      "781/781 [==============================] - 43s 55ms/step - loss: 0.3466 - acc: 0.9016 - val_loss: 0.4234 - val_acc: 0.8897\n",
      "Epoch 155/250\n",
      "781/781 [==============================] - 41s 52ms/step - loss: 0.3501 - acc: 0.9001 - val_loss: 0.4123 - val_acc: 0.8924\n",
      "Epoch 156/250\n",
      "781/781 [==============================] - 40s 52ms/step - loss: 0.3428 - acc: 0.9031 - val_loss: 0.4171 - val_acc: 0.8921\n",
      "Epoch 157/250\n",
      "781/781 [==============================] - 43s 55ms/step - loss: 0.3494 - acc: 0.8989 - val_loss: 0.4158 - val_acc: 0.8916\n",
      "Epoch 158/250\n",
      "781/781 [==============================] - 43s 55ms/step - loss: 0.3403 - acc: 0.9029 - val_loss: 0.4106 - val_acc: 0.8933\n",
      "Epoch 159/250\n",
      "781/781 [==============================] - 41s 52ms/step - loss: 0.3429 - acc: 0.9023 - val_loss: 0.4078 - val_acc: 0.8939\n",
      "Epoch 160/250\n",
      "781/781 [==============================] - 41s 52ms/step - loss: 0.3438 - acc: 0.9027 - val_loss: 0.4074 - val_acc: 0.8946\n",
      "Epoch 161/250\n",
      "781/781 [==============================] - 45s 57ms/step - loss: 0.3425 - acc: 0.9023 - val_loss: 0.4152 - val_acc: 0.8911\n",
      "Epoch 162/250\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.3458 - acc: 0.9007 - val_loss: 0.4250 - val_acc: 0.8894\n",
      "Epoch 163/250\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3438 - acc: 0.9022 - val_loss: 0.4200 - val_acc: 0.8900\n",
      "Epoch 164/250\n",
      "781/781 [==============================] - 43s 55ms/step - loss: 0.3406 - acc: 0.9030 - val_loss: 0.4179 - val_acc: 0.8904\n",
      "Epoch 165/250\n",
      "781/781 [==============================] - 44s 57ms/step - loss: 0.3394 - acc: 0.9035 - val_loss: 0.4199 - val_acc: 0.8902\n",
      "Epoch 166/250\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.3443 - acc: 0.9012 - val_loss: 0.4254 - val_acc: 0.8878\n",
      "Epoch 167/250\n",
      "781/781 [==============================] - 41s 52ms/step - loss: 0.3387 - acc: 0.9019 - val_loss: 0.4147 - val_acc: 0.8912\n",
      "Epoch 168/250\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3434 - acc: 0.9020 - val_loss: 0.4092 - val_acc: 0.8931\n",
      "Epoch 169/250\n",
      "781/781 [==============================] - 43s 56ms/step - loss: 0.3397 - acc: 0.9022 - val_loss: 0.4111 - val_acc: 0.8923\n",
      "Epoch 170/250\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.3421 - acc: 0.9023 - val_loss: 0.4230 - val_acc: 0.8887\n",
      "Epoch 171/250\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3366 - acc: 0.9046 - val_loss: 0.4232 - val_acc: 0.8883\n",
      "Epoch 172/250\n",
      "781/781 [==============================] - 40s 52ms/step - loss: 0.3419 - acc: 0.9016 - val_loss: 0.4106 - val_acc: 0.8936\n",
      "Epoch 173/250\n",
      "781/781 [==============================] - 44s 56ms/step - loss: 0.3426 - acc: 0.9027 - val_loss: 0.4100 - val_acc: 0.8926\n",
      "Epoch 174/250\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3359 - acc: 0.9068 - val_loss: 0.4067 - val_acc: 0.8937\n",
      "Epoch 175/250\n",
      "781/781 [==============================] - 43s 55ms/step - loss: 0.3417 - acc: 0.9026 - val_loss: 0.4123 - val_acc: 0.8942\n",
      "Epoch 176/250\n",
      "781/781 [==============================] - 44s 56ms/step - loss: 0.3408 - acc: 0.9025 - val_loss: 0.4028 - val_acc: 0.8946\n",
      "Epoch 177/250\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3390 - acc: 0.9044 - val_loss: 0.4167 - val_acc: 0.8897\n",
      "Epoch 178/250\n",
      "781/781 [==============================] - 45s 57ms/step - loss: 0.3405 - acc: 0.9032 - val_loss: 0.4102 - val_acc: 0.8909\n",
      "Epoch 179/250\n",
      "781/781 [==============================] - 44s 56ms/step - loss: 0.3345 - acc: 0.9037 - val_loss: 0.4053 - val_acc: 0.8940\n",
      "Epoch 180/250\n",
      "781/781 [==============================] - 44s 56ms/step - loss: 0.3369 - acc: 0.9042 - val_loss: 0.4204 - val_acc: 0.8906\n",
      "Epoch 181/250\n",
      "781/781 [==============================] - 43s 55ms/step - loss: 0.3338 - acc: 0.9056 - val_loss: 0.4152 - val_acc: 0.8892\n",
      "Epoch 182/250\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3385 - acc: 0.9039 - val_loss: 0.4132 - val_acc: 0.8894\n",
      "Epoch 183/250\n",
      "781/781 [==============================] - 44s 56ms/step - loss: 0.3388 - acc: 0.9030 - val_loss: 0.4032 - val_acc: 0.8925\n",
      "Epoch 184/250\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3354 - acc: 0.9058 - val_loss: 0.4165 - val_acc: 0.8891\n",
      "Epoch 185/250\n",
      "781/781 [==============================] - 45s 57ms/step - loss: 0.3388 - acc: 0.9035 - val_loss: 0.4065 - val_acc: 0.8930\n",
      "Epoch 186/250\n",
      "781/781 [==============================] - 44s 56ms/step - loss: 0.3384 - acc: 0.9037 - val_loss: 0.4172 - val_acc: 0.8896\n",
      "Epoch 187/250\n",
      "781/781 [==============================] - 43s 55ms/step - loss: 0.3336 - acc: 0.9046 - val_loss: 0.4066 - val_acc: 0.8935\n",
      "Epoch 188/250\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3366 - acc: 0.9039 - val_loss: 0.4157 - val_acc: 0.8902\n",
      "Epoch 189/250\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3330 - acc: 0.9041 - val_loss: 0.4047 - val_acc: 0.8941\n",
      "Epoch 190/250\n",
      "781/781 [==============================] - 46s 59ms/step - loss: 0.3365 - acc: 0.9040 - val_loss: 0.4166 - val_acc: 0.8891\n",
      "Epoch 191/250\n",
      "781/781 [==============================] - 44s 56ms/step - loss: 0.3323 - acc: 0.9064 - val_loss: 0.4000 - val_acc: 0.8951\n",
      "Epoch 192/250\n",
      "781/781 [==============================] - 43s 55ms/step - loss: 0.3362 - acc: 0.9041 - val_loss: 0.4072 - val_acc: 0.8950\n",
      "Epoch 193/250\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3343 - acc: 0.9046 - val_loss: 0.4074 - val_acc: 0.8934\n",
      "Epoch 194/250\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.3378 - acc: 0.9049 - val_loss: 0.4139 - val_acc: 0.8902\n",
      "Epoch 195/250\n",
      "781/781 [==============================] - 45s 58ms/step - loss: 0.3337 - acc: 0.9039 - val_loss: 0.4101 - val_acc: 0.8915\n",
      "Epoch 196/250\n",
      "781/781 [==============================] - 43s 55ms/step - loss: 0.3300 - acc: 0.9047 - val_loss: 0.4105 - val_acc: 0.8925\n",
      "Epoch 197/250\n",
      "781/781 [==============================] - 44s 56ms/step - loss: 0.3376 - acc: 0.9036 - val_loss: 0.4030 - val_acc: 0.8941\n",
      "Epoch 198/250\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3309 - acc: 0.9050 - val_loss: 0.4060 - val_acc: 0.8937\n",
      "Epoch 199/250\n",
      "781/781 [==============================] - 45s 58ms/step - loss: 0.3326 - acc: 0.9051 - val_loss: 0.4091 - val_acc: 0.8936\n",
      "Epoch 200/250\n",
      "781/781 [==============================] - 44s 57ms/step - loss: 0.3306 - acc: 0.9041 - val_loss: 0.4082 - val_acc: 0.8928\n",
      "Epoch 201/250\n",
      "781/781 [==============================] - 44s 57ms/step - loss: 0.3291 - acc: 0.9076 - val_loss: 0.4122 - val_acc: 0.8933\n",
      "Epoch 202/250\n",
      "781/781 [==============================] - 43s 55ms/step - loss: 0.3381 - acc: 0.9032 - val_loss: 0.4065 - val_acc: 0.8926\n",
      "Epoch 203/250\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3298 - acc: 0.9051 - val_loss: 0.4137 - val_acc: 0.8907\n",
      "Epoch 204/250\n",
      "781/781 [==============================] - 43s 55ms/step - loss: 0.3287 - acc: 0.9073 - val_loss: 0.4207 - val_acc: 0.8896\n",
      "Epoch 205/250\n",
      "781/781 [==============================] - 45s 58ms/step - loss: 0.3335 - acc: 0.9062 - val_loss: 0.4187 - val_acc: 0.8884\n",
      "Epoch 206/250\n",
      "781/781 [==============================] - 43s 55ms/step - loss: 0.3309 - acc: 0.9049 - val_loss: 0.4064 - val_acc: 0.8941\n",
      "Epoch 207/250\n",
      "781/781 [==============================] - 43s 55ms/step - loss: 0.3317 - acc: 0.9058 - val_loss: 0.4074 - val_acc: 0.8913\n",
      "Epoch 208/250\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3295 - acc: 0.9052 - val_loss: 0.4025 - val_acc: 0.8925\n",
      "Epoch 209/250\n",
      "781/781 [==============================] - 44s 57ms/step - loss: 0.3271 - acc: 0.9069 - val_loss: 0.4049 - val_acc: 0.8933\n",
      "Epoch 210/250\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3303 - acc: 0.9059 - val_loss: 0.4094 - val_acc: 0.8931\n",
      "Epoch 211/250\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3314 - acc: 0.9057 - val_loss: 0.4075 - val_acc: 0.8934\n",
      "Epoch 212/250\n",
      "781/781 [==============================] - 46s 59ms/step - loss: 0.3295 - acc: 0.9062 - val_loss: 0.4124 - val_acc: 0.8916\n",
      "Epoch 213/250\n",
      "781/781 [==============================] - 45s 57ms/step - loss: 0.3317 - acc: 0.9041 - val_loss: 0.4112 - val_acc: 0.8915\n",
      "Epoch 214/250\n",
      "781/781 [==============================] - 44s 57ms/step - loss: 0.3335 - acc: 0.9030 - val_loss: 0.4044 - val_acc: 0.8952\n",
      "Epoch 215/250\n",
      "781/781 [==============================] - 43s 56ms/step - loss: 0.3267 - acc: 0.9059 - val_loss: 0.4049 - val_acc: 0.8944\n",
      "Epoch 216/250\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3363 - acc: 0.9054 - val_loss: 0.4048 - val_acc: 0.8943\n",
      "Epoch 217/250\n",
      "781/781 [==============================] - 44s 57ms/step - loss: 0.3253 - acc: 0.9074 - val_loss: 0.4079 - val_acc: 0.8935\n",
      "Epoch 218/250\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3284 - acc: 0.9055 - val_loss: 0.4183 - val_acc: 0.8876\n",
      "Epoch 219/250\n",
      "781/781 [==============================] - 41s 53ms/step - loss: 0.3230 - acc: 0.9089 - val_loss: 0.4157 - val_acc: 0.8900\n",
      "Epoch 220/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3280 - acc: 0.9062 - val_loss: 0.4125 - val_acc: 0.8893\n",
      "Epoch 221/250\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3272 - acc: 0.9069 - val_loss: 0.3997 - val_acc: 0.8960\n",
      "Epoch 222/250\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3283 - acc: 0.9059 - val_loss: 0.4001 - val_acc: 0.8940\n",
      "Epoch 223/250\n",
      "781/781 [==============================] - 38s 49ms/step - loss: 0.3271 - acc: 0.9065 - val_loss: 0.4072 - val_acc: 0.8946\n",
      "Epoch 224/250\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3306 - acc: 0.9053 - val_loss: 0.4019 - val_acc: 0.8937\n",
      "Epoch 225/250\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3246 - acc: 0.9088 - val_loss: 0.4115 - val_acc: 0.8913\n",
      "Epoch 226/250\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3288 - acc: 0.9053 - val_loss: 0.4041 - val_acc: 0.8933\n",
      "Epoch 227/250\n",
      "781/781 [==============================] - 44s 56ms/step - loss: 0.3295 - acc: 0.9066 - val_loss: 0.4126 - val_acc: 0.8915\n",
      "Epoch 228/250\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3315 - acc: 0.9049 - val_loss: 0.3949 - val_acc: 0.8952\n",
      "Epoch 229/250\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3205 - acc: 0.9082 - val_loss: 0.3961 - val_acc: 0.8965\n",
      "Epoch 230/250\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3287 - acc: 0.9063 - val_loss: 0.4124 - val_acc: 0.8924\n",
      "Epoch 231/250\n",
      "781/781 [==============================] - 41s 52ms/step - loss: 0.3251 - acc: 0.9076 - val_loss: 0.4014 - val_acc: 0.8925\n",
      "Epoch 232/250\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3226 - acc: 0.9078 - val_loss: 0.4104 - val_acc: 0.8914\n",
      "Epoch 233/250\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3255 - acc: 0.9080 - val_loss: 0.4065 - val_acc: 0.8931\n",
      "Epoch 234/250\n",
      "781/781 [==============================] - 44s 56ms/step - loss: 0.3202 - acc: 0.9086 - val_loss: 0.4026 - val_acc: 0.8918\n",
      "Epoch 235/250\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3249 - acc: 0.9057 - val_loss: 0.4039 - val_acc: 0.8915\n",
      "Epoch 236/250\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3203 - acc: 0.9078 - val_loss: 0.4014 - val_acc: 0.8944\n",
      "Epoch 237/250\n",
      "781/781 [==============================] - 42s 54ms/step - loss: 0.3231 - acc: 0.9090 - val_loss: 0.4040 - val_acc: 0.8944\n",
      "Epoch 238/250\n",
      "781/781 [==============================] - 42s 53ms/step - loss: 0.3204 - acc: 0.9076 - val_loss: 0.4006 - val_acc: 0.8939\n",
      "Epoch 239/250\n",
      "781/781 [==============================] - 40s 52ms/step - loss: 0.3247 - acc: 0.9053 - val_loss: 0.4033 - val_acc: 0.8943\n",
      "Epoch 240/250\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3231 - acc: 0.9081 - val_loss: 0.4021 - val_acc: 0.8950\n",
      "Epoch 241/250\n",
      "781/781 [==============================] - 43s 55ms/step - loss: 0.3194 - acc: 0.9092 - val_loss: 0.3994 - val_acc: 0.8937\n",
      "Epoch 242/250\n",
      "781/781 [==============================] - 44s 56ms/step - loss: 0.3243 - acc: 0.9066 - val_loss: 0.4022 - val_acc: 0.8936\n",
      "Epoch 243/250\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3201 - acc: 0.9087 - val_loss: 0.3963 - val_acc: 0.8968\n",
      "Epoch 244/250\n",
      "781/781 [==============================] - 39s 50ms/step - loss: 0.3180 - acc: 0.9079 - val_loss: 0.4190 - val_acc: 0.8890\n",
      "Epoch 245/250\n",
      "781/781 [==============================] - 43s 55ms/step - loss: 0.3227 - acc: 0.9080 - val_loss: 0.4055 - val_acc: 0.8930\n",
      "Epoch 246/250\n",
      "781/781 [==============================] - 41s 52ms/step - loss: 0.3223 - acc: 0.9094 - val_loss: 0.4124 - val_acc: 0.8900\n",
      "Epoch 247/250\n",
      "781/781 [==============================] - 40s 52ms/step - loss: 0.3207 - acc: 0.9086 - val_loss: 0.3985 - val_acc: 0.8964\n",
      "Epoch 248/250\n",
      "781/781 [==============================] - 44s 56ms/step - loss: 0.3224 - acc: 0.9076 - val_loss: 0.4028 - val_acc: 0.8941\n",
      "Epoch 249/250\n",
      "781/781 [==============================] - 43s 55ms/step - loss: 0.3238 - acc: 0.9070 - val_loss: 0.4036 - val_acc: 0.8927\n",
      "Epoch 250/250\n",
      "781/781 [==============================] - 40s 51ms/step - loss: 0.3231 - acc: 0.9079 - val_loss: 0.4099 - val_acc: 0.8894\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbbe06fac88>"
      ]
     },
     "execution_count": 11,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#criar arquitetura do modelo\n",
    "\n",
    "#limite de plateau\n",
    "weight_decay = 1e-4\n",
    "\n",
    "#inicializar modelo\n",
    "classifier = Sequential()\n",
    "\n",
    "#1° Camada Convolucional\n",
    "classifier.add(Convolution2D(filters = 32, kernel_size = (3, 3), strides = (1, 1), padding = 'same', input_shape = (32, 32, 3), \n",
    "                             activation = 'elu', kernel_regularizer = regularizers.l2(weight_decay)))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "#2° Camada Convolucional\n",
    "classifier.add(Convolution2D(filters = 32, kernel_size = (3, 3), strides = (1, 1), padding = 'same', \n",
    "                             activation = 'elu', kernel_regularizer = regularizers.l2(weight_decay)))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "#1° Camada Max-Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n",
    "\n",
    "#1° Camada DropOut\n",
    "classifier.add(Dropout(0.2))\n",
    "\n",
    "#####\n",
    "\n",
    "#3° Camada Convolucional\n",
    "classifier.add(Convolution2D(filters = 64, kernel_size = (3, 3), strides = (1, 1), padding = 'same',\n",
    "                             activation = 'elu', kernel_regularizer = regularizers.l2(weight_decay)))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "#4° Camada Convolucional\n",
    "classifier.add(Convolution2D(filters = 64, kernel_size = (3, 3), strides = (1, 1), padding = 'same',\n",
    "                             activation = 'elu', kernel_regularizer = regularizers.l2(weight_decay)))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "#2° Camada Max-Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n",
    "\n",
    "#2° Camada Dropout\n",
    "classifier.add(Dropout(0.3))\n",
    "\n",
    "#####\n",
    "\n",
    "#5° Camada Convolucional\n",
    "classifier.add(Convolution2D(filters = 128, kernel_size = (3, 3), strides = (1, 1), padding = 'same',\n",
    "                             activation = 'elu', kernel_regularizer = regularizers.l2(weight_decay)))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "#6° Camada Convolucional\n",
    "classifier.add(Convolution2D(filters = 128, kernel_size = (3, 3), strides = (1, 1), padding = 'same',\n",
    "                             activation = 'elu', kernel_regularizer = regularizers.l2(weight_decay)))\n",
    "classifier.add(BatchNormalization())\n",
    "\n",
    "#3° Camada Max-Pooling\n",
    "classifier.add(MaxPooling2D(pool_size = (2, 2), strides = (2, 2)))\n",
    "\n",
    "#3° Camada Dropout\n",
    "classifier.add(Dropout(0.4))\n",
    "\n",
    "#Camada Flattening\n",
    "classifier.add(Flatten())\n",
    "\n",
    "#Camada Fully-connected\n",
    "classifier.add(Dense(units = dim_outputs, activation = 'softmax'))\n",
    "\n",
    "#Resumo do modelo\n",
    "classifier.summary()\n",
    "\n",
    "#Regularizacao com Data Argumentation\n",
    "datagen = ImageDataGenerator(rotation_range = 15, \n",
    "                             width_shift_range = 0.1, \n",
    "                             height_shift_range = 0.1, \n",
    "                            horizontal_flip = True)\n",
    "\n",
    "#algoritmo de otimizacao\n",
    "opt_rms = keras.optimizers.rmsprop(lr = 0.001, decay = 1e-4)\n",
    "\n",
    "#Compilar CNN\n",
    "classifier.compile(optimizer = opt_rms, loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "#fixar o modelo com o gerador\n",
    "\n",
    "def lr_control(epoch):\n",
    "    rate = 1e-3\n",
    "    if epoch > 50:\n",
    "        rate = 5e-4\n",
    "    elif epoch>125:\n",
    "        rate = 1e-4\n",
    "    return rate\n",
    "\n",
    "classifier.fit_generator(datagen.flow(x_train, y_train, batch_size = 64),\n",
    "                        steps_per_epoch = x_train.shape[0] // 64 , epochs = 250,\n",
    "                        validation_data = (x_test, y_test), verbose = 1,\n",
    "                        callbacks = [LearningRateScheduler(lr_control)])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "e05Wf2cXBUUl"
   },
   "outputs": [],
   "source": [
    "#armazenar o modelo em disco\n",
    "model_json = classifier.to_json()\n",
    "with open('cnn_cifar.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "classifier.save_weights('cnn_cifar.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nk1CgaOhcA8W"
   },
   "source": [
    "4) FASE DE AVALIAÇÃO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "c01ock0HcA8X",
    "outputId": "62f9e2fb-1a4e-4f77-ae01-0508ab22fe83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 11s 212us/step\n",
      "Acurácia-train:  94.838 %\n"
     ]
    }
   ],
   "source": [
    "#cálculo da acurácia no conjunto de treino\n",
    "score_train = classifier.evaluate(x_train, y_train, batch_size = 64)\n",
    "print('Acurácia-train: ', 100*score_train[1], '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "TO0tsAuzcA8f",
    "outputId": "229685b4-75fd-4f96-cfca-5f635903a19e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 2s 226us/step\n",
      "Acurácia-test:  88.94 %\n"
     ]
    }
   ],
   "source": [
    "#cálculo da acurácia no conjunto de teste\n",
    "score_test = classifier.evaluate(x_test, y_test, batch_size = 64)\n",
    "print('Acurácia-test: ', 100*score_test[1], '%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "StNau6x2cA8l"
   },
   "source": [
    "5) CONCLUSÕES:  \n",
    "Com o modelo de rede CNN proposta aplicada em 250 epochs executada sobre 1 Tesla K-80 GPU , os resultados são: \n",
    "- Acurácia no conjunto de treinamento: 94.84%\n",
    "- Acurácia no conjunto de teste: 88.94%"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CNN_cifar-holger_rivera.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
